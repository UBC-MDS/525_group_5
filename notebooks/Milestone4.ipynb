{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bb8edc9-ac2a-418d-82a1-0b2b834a50c3",
   "metadata": {},
   "source": [
    "## 3. Summarize your journey from Milestone 1 to Milestone 4\n",
    "rubric={mechanics:10}\n",
    ">There is no format or structure on how you write this. (also, no minimum number of words).  It's your choice on how well you describe it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0c8d8d-c1ca-49ee-a2a0-e08d0787e091",
   "metadata": {},
   "source": [
    "**Milestone 1**: We were working with a large dataset and recording the time taken and memory usage at each step on our personal computers. To reduce the time and memory usage, we used other optimization techniques such as \"converting numerical columns from float64 to float32\" and \"loading individual columns\" while doing the EDA. The conclusion we came to was that the M1 chip performs at 1.5 times the speed compared to the IntelCorei5 chip. Finally, to reduce time taken and memory usage, we explored different ways of saving a big data set by using the parquet and feather format.\n",
    "\n",
    "**Milestone 2**: Handling large files becomes a hassle on the local systems. Therefore we were introduced to Amazon Web Services (AWS). Here we set up an EC2 instance along with Jupyterhub, loaded the required packages and added users to it. We then set up a S3 bucket to store our files. We use the bucket to read and write out files. Then we go on to wrangle the dataset used in milestone 1 in a much lesser time and store it in the bucket.\n",
    "\n",
    "**Milestone 3**: In this milestone we will perform machine learning tasks. Since there is a limit to how much we can scale vertically, we scale horizontally by setting up an EMR cluster along with Spark, Hadoop, Jupyterhub along with the packages required. Then we went on to perform EDA and perform a randomforest regression on the overall and individual models. Then we find out the hyperparameters to it and store the model back into the S3 bucket.\n",
    "\n",
    "**Milestone 4**: In this milestone we deploy the model saved in the previous milestone and build the API to do it using Flask. We store the code in the bucket so that we can use it to perform the reading and writing tasks on it own and store it in the bucket. Then we created screen sessions to keep the API from stopping even if the user is offline. The API can run without Flask."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
